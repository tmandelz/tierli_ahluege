{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge: ccv1  \n",
    "# Deep Learning: Was versteckt sich da?  \n",
    "## Explorative Datenanalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plots\n",
    "save_plots = False\n",
    "path_plots = './plots/'\n",
    "\n",
    "# write cv-split as csv \n",
    "split_cv_csv = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erkenntnisse-Übersicht\n",
    "Kurz Übersicht welche Erkenntnisse aus der EDA-Analyse gezogen werden können:\n",
    "\n",
    "- Verteilung der Tierklassen auf dem Trainingsdatenset sind relativ ausgewogen und liegen zwischen 10-15%. Mit der Ausnahme von 'hogs' mit 6% Anteilnahme\n",
    "- Die Kamera Standorte nehmen sehr unterschiedlich viele Bilder auf, von einzelnen Bildern bis zu mehreren hundert Bildern.\n",
    "- Mit Ausnahme des Standorts 'S00060' sind jeweils unterschiedliche Tierarten in den Aufnahmen vertreten\n",
    "- Zum Bildformat wurden folgende Probleme festgestellt:\n",
    "    - Verschiedene Auflösungen sind vorhanden\n",
    "    - 83 % haben die Auflösung (640x360) oder (960, 540)\n",
    "    - die restlichen sind zugeschnittene Bilder oder mit einer tiefen Auflösungen\n",
    "    - Die Bildtiefe ist bei über 85% der Bilder bei 24bit und somit standard RGB, rund 15% sind schwarz-weiss Bilder mit 8Bit\n",
    "    - Die Bildtiefe kann je Standort unterschiedlich sein\n",
    "- Zum Bildinhalt wurden folgende Merkmale festgestellt\n",
    "    - Viele Bilder mit einem orangen Icon unten links und Datum/Zeit unten rechts vorhanden.\n",
    "    - Einige Bilder wurden bereits zugeschnitten (um wohl das Icon und Datum zu entfernen)\n",
    "    - Bei einige Aufnahmen sind die Tiere zu nahe an den Kameras (Bild unscharf oder dunkel)\n",
    "    - Bilder können überbelichtet sein\n",
    "    - Bilder können unscharf sein\n",
    "    - Bilder weisen Artefakte im Bild auf (z.B Standort der Kamera als Text im Bild)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhaltsverzeichnis\n",
    "1. CSV Daten lesen (Train, Test, Label)\n",
    "1. Klassifikation Tierarten\n",
    "1. Bilddaten Lesen (Train)  \n",
    "    1. Benchmark Ansicht  \n",
    "    1. Random Ansicht  \n",
    "    1. Problematische Bilder \n",
    "1. Verteilungen der Tierklassen\n",
    "1. Analyse zu Kamera Standorte (site ID)\n",
    "    1. Verteilung der Bilder je Standort (Train)\n",
    "    1. Plotten der Bilder je Standort\n",
    "1. Analyse zur Bildauflösung \n",
    "    1. Bilder und Bittiefe\n",
    "    1. Verteilung Tierklassen, Standort und Bittiefe\n",
    "1. Spezifische Kameramerkmale\n",
    "    1. Bild bearbeitung durch zuschneiden\n",
    "    1. Überbelichtung von Bildern prüfen\n",
    "1. Analysieren von Kamerastandorte\n",
    "    1. S0060 (civet_genet)\n",
    "1. Tests\n",
    "    1. Überbelichtung prüfen und beheben\n",
    "    1. Icon entfernen\n",
    "    1. Crossvalidation\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Daten Lesen (Train, Test, Label)\n",
    "Die CSV's beinhalten die Bild ID, Bildpfad, Aufnahmeort ID und die Tierklassifikation (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(\"../competition_data/train_features.csv\", index_col=\"id\")\n",
    "test_features = pd.read_csv(\"../competition_data/test_features.csv\", index_col=\"id\")\n",
    "train_labels = pd.read_csv(\"../competition_data/train_labels.csv\", index_col=\"id\")\n",
    "\n",
    "display(train_features.head())\n",
    "display(train_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse One-Hot-Encoding\n",
    "species_labels = sorted(train_labels.columns.unique())\n",
    "\n",
    "train_labels_cat = train_labels.copy()\n",
    "train_labels_cat['label'] = train_labels[species_labels].idxmax(axis=1)\n",
    "train_labels_cat = train_labels_cat.drop(species_labels, axis=1)\n",
    "\n",
    "display(train_labels_cat.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_label = train_features.merge(train_labels_cat, left_index=True, right_index=True)\n",
    "train_features_label.to_csv('train_features_label.csv', index=True)\n",
    "train_features_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation Tierarten\n",
    "Klassifikation findet für 8 Tierarten statt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(species_labels)\n",
    "print(f'Anzahl Tierklassen: {len(species_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('class_images/class_images.jpg')\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Klassen 'bird', 'rodent' umfassen mehrere Tierarten. Die Klasse 'blank' steht für ein Bild ohne ein Tier. Die übrigen Tierklassen sind im obigen Bild enthalten (Tierklassenbilder quelle: google)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilddaten Lesen (Train)\n",
    "Probeansicht Bilder (quelle: benchmark file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "path_img = '../competition_data/'\n",
    "\n",
    "# we'll create a grid with 8 positions, one for each label (7 species, plus blanks)\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(20, 20))\n",
    "\n",
    "# iterate through each species\n",
    "for species, ax in zip(species_labels, axes.flat):\n",
    "    # get an image ID for this species\n",
    "    img_id = (\n",
    "        train_labels[train_labels.loc[:,species] == 1]\n",
    "        .sample(1, random_state=random_state)\n",
    "        .index[0]\n",
    "    )\n",
    "    # reads the filepath and returns a numpy array\n",
    "    img = mpimg.imread(path_img + train_features.loc[img_id].filepath)\n",
    "    # plot etc\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"{img_id} | {species}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Ansicht\n",
    "Zelle mehrmals ausführen um unterschiedliche Bilder zu erhalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll create a grid with 8 positions, one for each label (7 species, plus blanks)\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(20, 20))\n",
    "\n",
    "# iterate through each species\n",
    "for species, ax in zip(species_labels, axes.flat):\n",
    "    # get an image ID for this species\n",
    "    img_id = (\n",
    "        train_labels[train_labels.loc[:,species] == 1]\n",
    "        .sample(1)\n",
    "        .index[0]\n",
    "    )\n",
    "    # reads the filepath and returns a numpy array\n",
    "    img = mpimg.imread(path_img + train_features.loc[img_id].filepath)\n",
    "    # plot etc\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"{img_id} | {species}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problematische Bilder \n",
    "Folgend wurden spezifisch Bilder herausgesucht um die Problematik von schlechten Bilder zu zeigen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_bad_img = ['ZJ015580', 'ZJ002746', 'ZJ007054', 'ZJ000888', 'ZJ010341', 'ZJ014451',\n",
    "                   'ZJ004927', 'ZJ007091', 'ZJ013234', 'ZJ013093', 'ZJ004451', 'ZJ010190',\n",
    "                   'ZJ002138', 'ZJ002196']\n",
    "example_good_img = ['ZJ003890', 'ZJ004925', 'ZJ012762', 'ZJ014396', 'ZJ015264', 'ZJ000895',\n",
    "                    'ZJ007334', 'ZJ004978', 'ZJ014157', 'ZJ010885']\n",
    "\n",
    "\n",
    "def plot_image_from_image_id(image_ids: list, nrows=4, ncols=3, figsize=(15, 15),\n",
    "                             fontsize=10, path='../competition_data/'):\n",
    "    # create grid \n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "\n",
    "    # iterate through each bad image\n",
    "    for idx, (img_id, ax) in enumerate(zip(image_ids, axes.flat)):\n",
    "        # get image label\n",
    "        img_label = train_labels_cat.loc[image_ids[idx]]['label']\n",
    "        # reads the filepath and returns a numpy array\n",
    "        img = mpimg.imread(path + train_features.loc[img_id].filepath)\n",
    "        # image dimension\n",
    "        width, height = Image.open(path_img + train_features.loc[img_id].filepath).size\n",
    "        # plot etc\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"{img_id} | {img_label} | {str(width)}x{str(height)}\", fontsize=fontsize)\n",
    "\n",
    "plot_image_from_image_id(example_bad_img)\n",
    "#plot_image_from_image_id(example_good_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgende Probleme zum Bildinhalt wurden bemerkt:\n",
    "- Viele Bilder mit einem orangen Icon unten links und Datum/Zeit unten rechts vorhanden.\n",
    "- Einige Bilder wurden bereits zugeschnitten um wohl das Icon und Datum zu entfernen.\n",
    "- Bei einige Aufnahmen sind die Tiere zu nahe an den Kameras (daher is das Bild unscharf oder dunkel)\n",
    "- Bilder können überbelichtet sein\n",
    "- Bilder können unscharf sein\n",
    "- Bilder weisen Artefakte im Bild auf (z.B Standort der Kamera als Text im Bild)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zu Prüfen: wenn die Bilder im Notebook mit den Bilder im File Ordner verglichen werden, fällt auf dass die Bilder in der Windowsansicht schwarz-weiss im Notebook jedoch blau-gelb angezeigt werden. Beispiel 'ZJ003494'.  \n",
    "Interpretation von mpimg prüfen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verteilungen der Tierklassen \n",
    "(Quelle: Benchmark)\n",
    "Wie im Benchmark Notebook beschrieben, entspricht die Tierklassen Verteilungen nicht dem eigentlichen Vorkommen. Die (Trainings)daten wurden für die Competition bereits vorbereitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_labels.sum().sort_values(ascending=False))\n",
    "display(train_labels.sum().divide(train_labels.shape[0]).sort_values(ascending=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse zu Kamera Standorte (site ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Anzahl Standort Training-Kameras: {len(train_features.site.unique())}')  \n",
    "print(f'Anzahl Standort Test-Kameras: {len(test_features.site.unique())}')\n",
    "\n",
    "print(f'Mittelwert: {len(train_features.site) / len(train_features.site.unique()):.0f} Bilder pro Ort, Train')\n",
    "print(f'Mittelwert: {len(test_features.site) / len(test_features.site.unique()):.0f} Bilder pro Ort, Test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verteilung der Bilder je Standort (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_site_count = train_features.groupby('site').count().reset_index().sort_values('filepath', ascending=True)\n",
    "\n",
    "# plot histgram\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.bar(df_site_count.site, df_site_count.filepath)\n",
    "plt.title('Anzahl Bilder je Kamera Standort (Trainset)', fontsize=20)\n",
    "plt.xlabel('site ID')\n",
    "plt.ylabel('counts')\n",
    "plt.xticks(rotation=90, fontsize=8)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y')\n",
    "if save_plots:\n",
    "    plt.savefig(path_plots + 'number_images_site.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insgesamt bestehen 148 verschiedene Kamera Standorte. Die ID-Nummerierung verläuft von S0001 bis S0198 (ID-Nummerierung nicht komplet durch numeriert). Die Verteilung zeigt die Anzahl Bilder die für einen Standort zur Verfügung stehen. Einige Standorte nehmen nur sehr wenige Bilder auf (1-2) ander enthalten hunderte Bilder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verteilung der Tierklassen je Standort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feature_labels = train_features.merge(train_labels_cat, left_index=True, right_index=True)\n",
    "df_train_feature_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked_plot = pd.crosstab(df_train_feature_labels['site'], df_train_feature_labels['label'])\n",
    "df_stacked_plot['max_count'] = df_stacked_plot.sum(axis=1)\n",
    "df_stacked_plot = df_stacked_plot.sort_values('max_count', ascending=True)\n",
    "df_stacked_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_stacked_classes_site(stacked_plot, min_count = 50, save_plot=False):\n",
    "    stacked_plot = stacked_plot[stacked_plot['max_count'] > min_count]\n",
    "    stacked_plot = stacked_plot.drop(columns='max_count')\n",
    "\n",
    "\n",
    "    stacked_plot.plot(kind='bar', stacked=True, figsize=(20,8))\n",
    "    plt.title('Vorkommen Tierklassen je Standort (Train)', fontsize=20)\n",
    "    plt.xlabel('site ID')\n",
    "    plt.ylabel('counts')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(axis='y')\n",
    "    if save_plots:\n",
    "        plt.savefig(path_plots + 'dist_animals_n_images_site.png', bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "plot_stacked_classes_site(df_stacked_plot, 50, save_plots)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotten von Bildern je Standort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'S0196'\n",
    "len(train_features[train_features['site'] == site])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_from_site_id(site_id: str, nrows=4, ncols=3, figsize=(15, 15), \n",
    "                            path='../competition_data/'):\n",
    "    # get images from site\n",
    "    img_site = train_features[train_features['site'] == site_id].reset_index()\n",
    "    img_site = img_site[0:nrows*ncols]\n",
    "    # create grid \n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "\n",
    "    # iterate through each bad image\n",
    "    for img_id, image_path, ax in zip(img_site.id, img_site.filepath, axes.flat):\n",
    "        # reads the filepath and returns a numpy array\n",
    "        img = mpimg.imread(path + image_path)\n",
    "         # get image label\n",
    "        img_label = train_labels_cat.loc[img_id]['label']\n",
    "        # plot\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"{img_id} | {img_label}\")\n",
    "\n",
    "plot_image_from_site_id(site)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse zu Bildauflösung \n",
    "Hier soll geprüft werden wie stark die Auflösungen der Kameras varrieren. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Auflösungen kann mit 'mpimg' durch shape wiedergegeben werden. Eine schneller Möglichkeit ist 'Pillow' zu verwenden, die Bittiefe muss jedoch seperate mit [getbands()](https://pillow.readthedocs.io/en/stable/handbook/concepts.html) ausgelesen werden. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_to_bpp = {'1':1, 'L':8, 'P':8, 'RGB':24, 'RGBA':32, 'CMYK':32, 'YCbCr':24, 'I':32, 'F':32}\n",
    "\n",
    "img_id = []\n",
    "img_width = []\n",
    "img_height = []\n",
    "img_dim = []\n",
    "band_mode = []\n",
    "bit_depth = []\n",
    "\n",
    "for imag_id in train_features.reset_index().id:\n",
    "    # get id and dimensions\n",
    "    img = Image.open(path_img + train_features.loc[imag_id].filepath)\n",
    "    width, height = img.size\n",
    "    dim = img.size\n",
    "    mode = img.getbands()\n",
    "\n",
    "    # save to list\n",
    "    img_id.append(imag_id)\n",
    "    img_width.append(width)\n",
    "    img_height.append(height)\n",
    "    img_dim.append(dim)\n",
    "    band_mode.append(mode)\n",
    "\n",
    "df_img_shape_pil = pd.DataFrame({'id': img_id, 'width': img_width, 'height': img_height, \n",
    "                                 'dim':img_dim, 'band_mode': band_mode})\n",
    "\n",
    "df_img_shape_pil.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dim = df_img_shape_pil.dim.value_counts().reset_index().sort_values('dim', ascending=False)\n",
    "unique_dim = unique_dim.rename(columns={'dim': 'count', 'index': 'dim'})\n",
    "unique_dim['count_relativ'] = np.round(unique_dim['count'] / sum(unique_dim['count']), 2)\n",
    "display(unique_dim.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "fontsize = 8\n",
    "\n",
    "ax[0].bar(np.arange(len(unique_dim)), unique_dim['count'])\n",
    "ax[0].set_xticks(np.arange(len(unique_dim)), unique_dim.dim)\n",
    "ax[0].set_title('Verteilung der Bildauflösungen')\n",
    "ax[0].set_ylabel('counts', fontsize=fontsize)\n",
    "ax[0].tick_params(axis='y', labelsize=fontsize)\n",
    "ax[0].set_xticklabels(unique_dim.dim, rotation=60)\n",
    "\n",
    "for i, v in enumerate(unique_dim['count']):\n",
    "    ax[0].text(i, v, str(v), ha='center', va='bottom', fontsize=fontsize)\n",
    "\n",
    "ax[1].bar(np.arange(len(unique_dim)), unique_dim['count_relativ'] )\n",
    "ax[1].set_xticks(np.arange(len(unique_dim)), unique_dim.dim)\n",
    "ax[1].set_title('Verteilung der Bildauflösungen [relativ]')\n",
    "ax[1].set_ylabel('counts', fontsize=fontsize)\n",
    "ax[1].tick_params(axis='y', labelsize=fontsize)\n",
    "ax[1].set_xticklabels(unique_dim.dim, rotation=60)\n",
    "\n",
    "\n",
    "for i, v in enumerate(unique_dim['count_relativ']):\n",
    "    ax[1].text(i, v, str(v*100)+'%', ha='center', va='bottom', fontsize=fontsize)\n",
    "    \n",
    "if save_plots:\n",
    "    plt.savefig(path_plots + 'dist_image_resolution.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Über 80% der Bilder haben die Auflösung (640, 360) oder (960, 540)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilder und Bittiefe\n",
    "Die Bittiefe beschreibt wie viele Bits zur Darstellung von Farben eines Pixels zur Verfügung stehen. Standard ist 24Bit, 8Bit für jeden Farbkanal von RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bit_depth = df_img_shape_pil['band_mode'].value_counts().reset_index(name='count')\n",
    "df_bit_depth = df_bit_depth.rename(columns={'index':'mode'})\n",
    "df_bit_depth['count_rel'] = df_bit_depth['count'] / df_bit_depth['count'].sum()\n",
    "df_bit_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bit_depth = df_img_shape_pil['band_mode'].value_counts().reset_index(name='count')\n",
    "df_bit_depth = df_bit_depth.rename(columns={'index':'mode'})\n",
    "# add relativ count\n",
    "df_bit_depth['count_rel'] = df_bit_depth['count'] / df_bit_depth['count'].sum()\n",
    "df_bit_depth.plot(x='mode', y='count_rel', kind='bar', figsize=(6,4))\n",
    "plt.suptitle('Verteilung Bit Tiefe Bilder', fontsize=12)\n",
    "plt.title('RGB: 24bit, L: 8bit', fontsize=8)\n",
    "plt.xlabel('band mode')\n",
    "plt.ylabel('count relativ')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid()\n",
    "if save_plots:\n",
    "    plt.savefig(path_plots + 'dist_image_depth.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Über 80% der Bilder haben 24Bit Farbtiefe (RGB), die restlichen bestehen aus 8Bit (L) für monochrom oder schwarz-weiss Bilder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bittiefe je Kamerastandort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feature_labels_dim = df_train_feature_labels.merge(df_img_shape_pil[['id', 'dim', 'band_mode']], left_index=True, right_on='id')\n",
    "df_train_feature_labels_dim = df_train_feature_labels_dim.set_index('id')\n",
    "df_train_feature_labels_dim['dim'] = df_train_feature_labels_dim['dim'].astype(str)\n",
    "df_train_feature_labels_dim['band_mode'] = df_train_feature_labels_dim['band_mode'].astype(str)\n",
    "df_train_feature_labels_dim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked_plot_bit = pd.crosstab(df_train_feature_labels_dim['site'], df_train_feature_labels_dim['band_mode'])\n",
    "\n",
    "# sort values\n",
    "df_stacked_plot_bit['max_count'] = df_stacked_plot_bit.sum(axis=1)\n",
    "df_stacked_plot_bit = df_stacked_plot_bit.sort_values('max_count', ascending=True)\n",
    "df_stacked_plot_bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 0\n",
    "stacked_plot_bit = df_stacked_plot_bit[df_stacked_plot_bit['max_count'] >= min_count].copy()\n",
    "stacked_plot_bit = stacked_plot_bit.drop(columns='max_count')\n",
    "print(len(stacked_plot_bit))\n",
    "\n",
    "stacked_plot_bit.plot(kind='bar', stacked=True, figsize=(20,6))\n",
    "plt.title('Bild Bittiefe je Standort (Train)', fontsize=20)\n",
    "plt.xlabel('site ID')\n",
    "plt.ylabel('counts')\n",
    "plt.xticks(rotation=90, fontsize=8)\n",
    "plt.grid(axis='y')\n",
    "if save_plots:\n",
    "    plt.savefig(path_plots + 'image_depth_site.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Überraschen ist dass die Kamerastandort unterschiedliche Bittiefen haben (Beispiel S0014). Es wurden evtl unterschiedliche Kameras pro Standort verwendet oder die Nachtaufnahmen werden in schwarz-weiss erstellt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verteilung Tierklassen Biettiefe und Site\n",
    "Hier soll untersucht werden ob die schwarz-weiss Aufnahmen von den Tierklassen abhängig sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feature_labels_dim.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in species_labels:    \n",
    "    df_train_feature_labels_dim_x = df_train_feature_labels_dim[df_train_feature_labels_dim['label'] == label]\n",
    "\n",
    "    df_stacked_plot_bit = pd.crosstab(df_train_feature_labels_dim_x['site'], df_train_feature_labels_dim_x['band_mode'])\n",
    "\n",
    "    # sort values\n",
    "    df_stacked_plot_bit['max_count'] = df_stacked_plot_bit.sum(axis=1)\n",
    "    df_stacked_plot_bit = df_stacked_plot_bit.sort_values('max_count', ascending=True)\n",
    "    df_stacked_plot_bit.tail()\n",
    "\n",
    "    # filter values\n",
    "    min_count = 0\n",
    "    stacked_plot_bit = df_stacked_plot_bit[df_stacked_plot_bit['max_count'] >= min_count].copy()\n",
    "    stacked_plot_bit = stacked_plot_bit.drop(columns='max_count')\n",
    "\n",
    "    # plot \n",
    "    stacked_plot_bit.plot(kind='bar', stacked=True, figsize=(20,5))\n",
    "    plt.title(f'Bild Bittiefe je Standort: {label} (Trainset)', fontsize=20)\n",
    "    plt.xlabel('site ID')\n",
    "    plt.ylabel('counts')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(axis='y')\n",
    "    if save_plots:\n",
    "        plt.savefig(f'{path_plots}dist_bitdepth_site_{label}.png', bbox_inches=\"tight\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es scheint dass viele der monochrom Bilder ohne enthaltene Tiere erstellt werden, Klasse 'blank'. Ein Muster für Nachtaktive Tiere kann nicht direkt abgeleitet werden. Festzustellen ist dass die Tierklassen, relative gut verteilt, an vielen Kamera Standorte erfasst werden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spezifische Kameramerkmale\n",
    "Am unteren Rand haben viele Bilder das gleiche Logo und Zeitstempfel. Auf verschiedenen Bildern wurden diese teilweise durch beschneiden entfernt. Hier soll untersucht werden: \n",
    "- ob Aussagen über die Bearbeitung gemacht werden können (z.B. unterer Teil entfert)?\n",
    "- kann durch die Auflösung auf eine Bearbeitung geschlossen werden?\n",
    "- habe Standort bestimmte Eigenschaft?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bild bearbeitung durch zuschneiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images with Logo and time:\n",
    "img_logo_time = ['ZJ000001', 'ZJ000002', 'ZJ000003', 'ZJ000005',\n",
    "                 'ZJ000006', 'ZJ000025', 'ZJ000026', 'ZJ000031', 'ZJ000140']\n",
    "\n",
    "\n",
    "plot_image_from_image_id(img_logo_time, nrows=3, figsize=(10, 7), fontsize=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die neun Testbilder gehören alle zu beiden Hauptgruppen der Bildauflösungen, (640x360) und (960x540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images cut\n",
    "img_logo_time_cut = ['ZJ000004', 'ZJ000053', 'ZJ000063', 'ZJ000090',\n",
    "                 'ZJ000099', 'ZJ000106', 'ZJ000114', 'ZJ000119', 'ZJ000156']\n",
    "\n",
    "plot_image_from_image_id(img_logo_time_cut, nrows=3, figsize=(10, 7), fontsize=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die neun Testbilder, bei denen das Logo und Zeitstempfel teilweise entfernt wurde, haben jeweils eine Beschneidung in der Dimension 'height'. Daraus könnte geschlossen werden dass die bearbeiteten Bilder der Hauptgruppe angehören jedoch mit fehlendem unterem Abschnitt, (640x360) -> (640x**335**) und (960x540) -> (960x**515**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special cases\n",
    "img_special_case = ['ZJ000019', 'ZJ000015', 'ZJ000016', 'ZJ000018',\n",
    "                 'ZJ000065', 'ZJ000124', 'ZJ000132', 'ZJ000139', 'ZJ000142']\n",
    "\n",
    "plot_image_from_image_id(img_special_case, nrows=3, figsize=(10, 7), fontsize=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Überbelichtung bei Bilder prüfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overexposed(image_path, threshold=220):\n",
    "    '''\n",
    "    high threshold for high brightness\n",
    "    '''\n",
    "    # Öffnen des Bildes mit Pillow\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Berechnung der durchschnittlichen Helligkeit des Bildes\n",
    "    brightness = sum(image.convert('L').getdata()) / (image.width * image.height)\n",
    "\n",
    "    # Überprüfung, ob die Helligkeit über dem Schwellenwert liegt\n",
    "    return brightness > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_overexposed = {}\n",
    "\n",
    "for im_path in train_features['filepath'].head(100):\n",
    "    path = path_img + im_path\n",
    "\n",
    "    # check image is overexposed\n",
    "    if is_overexposed(path, threshold=220):\n",
    "        image_name = os.path.split(path)[1].split('.')[0]\n",
    "        images_overexposed[image_name] = im_path\n",
    "\n",
    "print(f'Found {len(images_overexposed)} Images')\n",
    "\n",
    "# plot images\n",
    "images_overexposed_ids = list(images_overexposed.keys())\n",
    "plot_image_from_image_id(images_overexposed_ids, nrows=1, figsize=(10, 7), fontsize=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysieren von Kamerastandorte\n",
    "### S0060, civet_genet\n",
    "Der Standort S0060 zeigt in der Verteilung einen überproporzionalen Anteil der Tierklasse `civet_genet`. Folgend sollen die Bilder dieses Standortes untersucht werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_site_count[df_site_count['filepath'] > 600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_S0060 = 'S0060'\n",
    "plot_image_from_site_id(site_S0060)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erkenntnisse der manuellen Untersuchung der Bilder:**  \n",
    "* auf den Bildern sind tatsächlich sehr viele `Civet Genet` an unterschiedlichen Bildorten abgebildet. Kamera evtl direkt neben `Civet Genet` Bau oder in dessen Revier aufgebaut\n",
    "* die Bildernamen ergeben keine Rückschlüsse auf deren Aufnahmezeit (die Reihenfolge der Bildernamen entsprechen nicht der Reihenfolge der Datumangabe des Zeitstempels im Bild). Es sind auch keine Metadaten über die Aufnahmezeit vorhanden. Der Nachweis eines `Burst-Effekts` ist also schwierig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following code copys the site images from S0060 to the eda folder\n",
    "create_folder_S0060_with_images = False\n",
    "\n",
    "# Filter for S0060 and civet_genet\n",
    "filter_S0060 = train_features_label[(train_features_label['site'] == site_S0060) & (train_features_label['label'] == 'civet_genet')]['filepath']\n",
    "# get image names\n",
    "S0060_images = filter_S0060.str.split('/', expand=True)[1]\n",
    "S0060_images\n",
    "\n",
    "if create_folder_S0060_with_images:\n",
    "    # create folder for site S0060\n",
    "    folder_name = \"site_S0060\"\n",
    "    folder_S0060_path = \"./\"    \n",
    "    folder_S0060_path = os.path.join(folder_S0060_path, folder_name)\n",
    "\n",
    "    if not os.path.exists(folder_S0060_path):\n",
    "        os.makedirs(folder_S0060_path)\n",
    "\n",
    "    # Copy S0060 images to folder ./S0060\n",
    "    source_path = '../competition_data/train_features/'\n",
    "    for filename in os.listdir('../competition_data/train_features/'):\n",
    "        if filename in list(S0060_images):\n",
    "            #shutil.copy(source_path, folder_S0060_path)\n",
    "            filname_id = filename[:-4]\n",
    "            img = mpimg.imread(path_img + train_features.loc[filname_id].filepath)\n",
    "            mpimg.imsave(folder_S0060_path + '/' + filename, img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Untersuchungen zur Überbelichtung**   \n",
    "Auch mit tieferem `treshold=200` wurden keine Überbelichtete Bilder gefunden. Falls die Bilder zu `Civet Genet` reduziert werden sollen, eignet sich die Prüfung nach der Helligkeit der Bilder nicht. Eine zufällige manuelle Ansicht zeigte dass `Civet Genet` auf den hellen Bildern teilweise besser ersichtlich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_overexposed_S0060 = {}\n",
    "\n",
    "for im_path in filter_S0060:\n",
    "    path = path_img + im_path\n",
    "\n",
    "    # check image is overexposed\n",
    "    if is_overexposed(path, threshold=200):\n",
    "        image_name = os.path.split(path)[1].split('.')[0]\n",
    "        images_overexposed[image_name] = im_path\n",
    "\n",
    "print(f'Found {len(images_overexposed_S0060)} overexposed Images')\n",
    "\n",
    "# plot images\n",
    "#images_overexposed_S0060_ids = list(images_overexposed_S0060.keys())\n",
    "#plot_image_from_image_id(images_overexposed_S0060_ids, nrows=1, figsize=(10, 7), fontsize=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazit: Falls die Anzahl der Tierklasse `Civet Genet` für den Standort `S0060` begrenzt werden möchte, kann dies zufällig gemacht werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Anpassungen von Überbelichteten Bildern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(images_overexposed.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_id, path in images_overexposed.items():\n",
    "    path = path_img + path\n",
    "    img = Image.open(path)\n",
    "    img.save(f\"./enhanced_images/{image_id}_pre_enh.jpg\")\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    # to reduce brightness by 50%, use factor 0.5\n",
    "    img = enhancer.enhance(0.5)\n",
    "\n",
    "    img.save(f\"./enhanced_images/{image_id}_post_enh.jpg\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Icon entfernen\n",
    "Hier soll versucht werden ob das Logo im linken unteren Teil des Bildes automatisch erkannt werden kann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop image\n",
    "def crop_image_for_logo(pillow_image, plot_image=False):\n",
    "    # dim img\n",
    "    width, height = img.size\n",
    "\n",
    "    # crop images, left corner\n",
    "    crop_height = height * 0.09\n",
    "    crop_width = width * 0.95\n",
    "\n",
    "    x1 = 0\n",
    "    y1 = height - crop_height\n",
    "    x2 = width - crop_width\n",
    "    y2 = height\n",
    "\n",
    "    cropped_img = img.crop((x1, y1, x2, y2))\n",
    "\n",
    "    if plot_image:\n",
    "        plt.imshow(cropped_img)\n",
    "        plt.show()\n",
    "\n",
    "    return cropped_img\n",
    "\n",
    "# get image main color\n",
    "def get_img_main_color(pillow_imag, print_info=False):\n",
    "    # Wandle das Bild in den RGB-Modus um, falls es noch nicht im RGB-Modus vorliegt.\n",
    "    if pillow_imag.mode != \"RGB\":\n",
    "        pillow_imag = pillow_imag.convert(\"RGB\")\n",
    "\n",
    "    # Extrahiere die Farb-Kanäle aus dem Bild.\n",
    "    r, g, b = pillow_imag.split()[0], pillow_imag.split()[1], pillow_imag.split()[2]\n",
    "\n",
    "    # Berechne den durchschnittlichen Wert des Kanals.\n",
    "    mean_r = sum(r.getdata()) / len(r.getdata())\n",
    "    mean_g = sum(g.getdata()) / len(g.getdata())\n",
    "    mean_b = sum(b.getdata()) / len(b.getdata())\n",
    "\n",
    "    mean_rgb = {'red': mean_r, 'green': mean_g, 'blue': mean_b}\n",
    "\n",
    "    max_mean_color = max(mean_rgb, key=lambda x:mean_rgb[x])\n",
    "    if print_info:\n",
    "        print(f'image is mostly: {max_mean_color}')\n",
    "        return\n",
    "    \n",
    "    return max_mean_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image\n",
    "img = Image.open(path_img + train_features.loc['ZJ000001'].filepath)\n",
    "\n",
    "# crop image\n",
    "cropped_image = crop_image_for_logo(img, plot_image=True)\n",
    "\n",
    "# get main color image\n",
    "get_img_main_color(cropped_image, print_info=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_cross_split = df_site_count.reset_index(drop=True)\n",
    "bins = np.append(0,np.sort(np.append(148,148-np.cumsum((148//5 + 1) * [5])))[1:])\n",
    "df_for_cross_split=pd.concat([df_for_cross_split,pd.DataFrame(pd.cut(df_for_cross_split.index, bins=bins, include_lowest=True))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#added some parameters\n",
    "n_animals = []\n",
    "splits=[]\n",
    "kf=StratifiedKFold(n_splits = 5, shuffle = True,random_state=49)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_for_cross_split[0])\n",
    "for n,(train,test) in enumerate(kf.split(np.zeros(len(y)),y)):\n",
    "    n_animals.append(np.sum(df_for_cross_split.iloc[test][\"filepath\"]))\n",
    "    df_for_cross_split.loc[test,\"split\"] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_train_feature_labels = pd.merge(df_train_feature_labels_dim,df_for_cross_split.loc[:,[\"site\",\"split\"]],on=\"site\")\n",
    "df_stacked_plot_bit = pd.crosstab(cross_val_train_feature_labels['split'], cross_val_train_feature_labels['band_mode'])\n",
    "df_stacked_plot_bit = df_stacked_plot_bit.div(df_stacked_plot_bit.sum(1), axis=0).mul(100)\n",
    "\n",
    "df_stacked_plot_bit.plot(kind='bar', stacked=True, figsize=(20,6))\n",
    "plt.title('Bild Bittiefe je Standort (Train)', fontsize=20)\n",
    "plt.xlabel('split_id')\n",
    "plt.ylabel('counts')\n",
    "plt.xticks(rotation=90, fontsize=8)\n",
    "plt.grid(axis='y')\n",
    "if save_plots:\n",
    "    plt.savefig(path_plots + 'image_depth_site.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked_plot = pd.crosstab(cross_val_train_feature_labels['split'], cross_val_train_feature_labels['label'])\n",
    "df_stacked_plot = df_stacked_plot.div(df_stacked_plot.sum(1), axis=0).mul(100)\n",
    "\n",
    "df_stacked_plot.plot(kind='bar', stacked=True, figsize=(20,8))\n",
    "plt.title('Vorkommen Tierklassen je Standort (Train)', fontsize=20)\n",
    "plt.xlabel('split')\n",
    "plt.ylabel('Percentage per split')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y')\n",
    "if save_plots:\n",
    "    plt.savefig(path_plots + 'dist_animals_n_images_site.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_with_split = pd.merge(train_features.reset_index(),cross_val_train_feature_labels.loc[:,[\"filepath\",\"split\"]],on=\"filepath\",how= \"left\")\n",
    "train_labels_with_split = pd.merge(train_labels.reset_index(),train_features_with_split.loc[:,[\"id\",\"split\"]],on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split_cv_csv:\n",
    "    train_features_with_split.to_csv(\"../competition_data/train_features_with_split.csv\",index=False)\n",
    "    train_labels_with_split.to_csv(\"../competition_data/train_labels_with_split.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tierli_ahluege-kxyn7EyL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
