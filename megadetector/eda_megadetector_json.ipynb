{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_threshold = 0.6\n",
    "save_csv_file = False\n",
    "save_plots = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json Daten Megedetectron lesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_label = pd.read_csv(\"../eda/train_features_label.csv\", index_col='id')\n",
    "\n",
    "mega_json = json.load(open('train_features_output.json'))\n",
    "mega_json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_detection_cat = mega_json['detection_categories']\n",
    "dict_detection_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_detector_info = mega_json['info']\n",
    "mega_detector_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images = pd.DataFrame(mega_json[\"images\"])\n",
    "df_images = df_images.reset_index(drop=True)\n",
    "df_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# several bbox per image possible\n",
    "df_images['detections'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten in geeignetes Format bringen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_megadetector_json(path_json:str = 'train_features_output.json'):\n",
    "    mega_json = json.load(open(path_json))\n",
    "\n",
    "    df_images = pd.DataFrame(mega_json[\"images\"])\n",
    "    df_images = df_images.reset_index(drop=True)\n",
    "    return df_images\n",
    "\n",
    "def transform_bbox(image=None, normalized_bbox=None, image_size:int=None):\n",
    "    if image is not None:\n",
    "        image_width, image_height = image.size\n",
    "    else:\n",
    "        image_width, image_height = image_size, image_size\n",
    "        \n",
    "    x, y, width, height = normalized_bbox\n",
    "    remove_bbox_xy = 4\n",
    "    remove_bbox_wh = remove_bbox_xy * 2\n",
    "\n",
    "    x = int(np.round(x * image_width, 0)) + remove_bbox_xy\n",
    "    y = int(np.round(y * image_height, 0)) + remove_bbox_xy\n",
    "    width = int(np.round(width * image_width, 0)) - remove_bbox_wh\n",
    "    height = int(np.round(height * image_height, 0)) - remove_bbox_wh\n",
    "    return y, x, height, width\n",
    "\n",
    "def get_correct_box(df, train_data):\n",
    "    bbox_transformed = []\n",
    "    bbox_transformed_im_size_224 = []\n",
    "    image_size = 224\n",
    "    if train_data: \n",
    "        data_path = r\"../competition_data/train_features/\"\n",
    "    else:\n",
    "        data_path = r\"../competition_data/test_features/\"\n",
    "\n",
    "    for image_name in df.index:\n",
    "        if df.loc[image_name][\"bbox_true\"]:\n",
    "            path = data_path + df.loc[image_name][\"file\"]\n",
    "            image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "            normalized_bbox = df.loc[image_name]['bbox_normalized']\n",
    "            bbox_transformed.append(transform_bbox(image=image, normalized_bbox=normalized_bbox))\n",
    "            bbox_transformed_im_size_224.append(transform_bbox(normalized_bbox=normalized_bbox, image_size=image_size))\n",
    "        else:\n",
    "            bbox_transformed.append(pd.NA)\n",
    "            bbox_transformed_im_size_224.append(pd.NA)\n",
    "\n",
    "    df['bbox'] = bbox_transformed\n",
    "    df['bbox_im_size_224'] = bbox_transformed_im_size_224\n",
    "    return df\n",
    "\n",
    "def get_clean_dataframe_from_json(threshold:float=0.6, save_csv=False, filter_th=True, train_data=True):\n",
    "    '''\n",
    "    filter: filters bbox below threshold if true\n",
    "    '''\n",
    "\n",
    "    df_images = read_megadetector_json()\n",
    "\n",
    "    df_images_detections = df_images['detections'].apply(pd.Series, dtype='object')\n",
    "    #display(df_images_detections.head(2))\n",
    "\n",
    "    df_images_clean = df_images.merge(df_images_detections, left_index=True, right_index=True).drop(columns='detections')\n",
    "    #display(df_images_clean.head(2))\n",
    "\n",
    "    df_images_clean = df_images_clean.melt(id_vars=['file', 'max_detection_conf']).sort_values('file')\n",
    "    #display(df_images_clean)\n",
    "\n",
    "    # remove nan values \n",
    "    df_images_clean = df_images_clean.dropna(subset='value')\n",
    "    df_images_clean = df_images_clean.drop(columns='variable')\n",
    "\n",
    "    # expand category, conf, bbox\n",
    "    df_cat_conf_bbox = df_images_clean['value'].apply(pd.Series, dtype='object')\n",
    "    df_images_clean = df_images_clean.merge(df_cat_conf_bbox, left_index=True, right_index=True).drop(columns='value')\n",
    "\n",
    "    # take only detections for max detection conf\n",
    "    df_images_clean = df_images_clean[df_images_clean['max_detection_conf'] == df_images_clean['conf']]\n",
    "    df_images_clean = df_images_clean.reset_index(drop=True)\n",
    "\n",
    "    # leftjoin clean data\n",
    "    df_images_clean = pd.merge(df_images['file'], df_images_clean, on='file', how='left')\n",
    "\n",
    "    # cast datatypes\n",
    "    df_images_clean['category'] = df_images_clean['category'].astype('category')\n",
    "    df_images_clean['category'] = df_images_clean['category'].replace(dict_detection_cat)\n",
    "\n",
    "    # change index to image name\n",
    "    df_images_clean['image_name'] = [image.replace('.jpg', '') for image in df_images_clean['file']]\n",
    "    df_images_clean.index = df_images_clean['image_name']\n",
    "    df_images_clean = df_images_clean.drop(columns='image_name')\n",
    "\n",
    "    # remove duplicates\n",
    "    df_images_clean = df_images_clean[df_images_clean.index.duplicated() == False]\n",
    "\n",
    "    # bbox\n",
    "    df_images_clean['bbox_normalized'] = df_images_clean['bbox']\n",
    "    df_images_clean['bbox_true'] = df_images_clean['bbox_normalized'].notnull()\n",
    "\n",
    "    # transform bbox\n",
    "    df_images_clean = get_correct_box(df_images_clean, train_data)\n",
    "\n",
    "    if filter_th: \n",
    "        df_images_clean = df_images_clean[df_images_clean['max_detection_conf'] > threshold]\n",
    "        \n",
    "    if save_csv: df_images_clean.to_csv(f'megadetector_image_detection_bbox_th{str(threshold).replace(\".\", \"\")}.csv')\n",
    "\n",
    "    return df_images_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the quality of the bounding boxes for all confidence levels with filter_th=False.\n",
    "df_images_clean = get_clean_dataframe_from_json(0, save_csv=False, filter_th=False)\n",
    "df_images_clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Untersuche Kategorien  \n",
    "Das Modell des Megadetectors unterscheidet zwischen drei Kategorien: `Animal`, `Person`, `Vehicle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images_clean['category'].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (8, 4)\n",
    "\n",
    "figure = plt.figure(figsize=figsize)\n",
    "df_images_clean['category'].value_counts().plot.bar()\n",
    "cat_na = df_images_clean.shape[0]- df_images_clean['category'].value_counts().sum()\n",
    "plt.title(f'Verteilung der detektierten Kategorien, na:{cat_na}')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "if save_plots: plt.savefig('./plots/dist_detection_classes.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=figsize)\n",
    "df_images_clean[df_images_clean['category'] == 'animal']['max_detection_conf'].plot.hist()\n",
    "plt.title('Verteilung von max_detection_conf für Kategorie 1 (Animal)')\n",
    "plt.xlabel('max_detection_conf')\n",
    "plt.tight_layout()\n",
    "if save_plots: plt.savefig('./plots/dist_conf_animal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=figsize)\n",
    "df_images_clean[df_images_clean['category'] == 'person']['max_detection_conf'].plot.hist()\n",
    "plt.title('Verteilung von max_detection_conf für Kategorie 2 (Person)')\n",
    "plt.xlabel('max_detection_conf')\n",
    "plt.tight_layout()\n",
    "if save_plots: plt.savefig('./plots/dist_conf_person.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=figsize)\n",
    "df_images_clean[df_images_clean['category'] == 'vehicle']['max_detection_conf'].plot.hist()\n",
    "plt.title('Verteilung von max_detection_conf für Kategorie 3 (vehicle)')\n",
    "plt.xlabel('max_detection_conf')\n",
    "plt.tight_layout()\n",
    "if save_plots: plt.savefig('./plots/dist_conf_vehicle.png')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prüfe einzelne Bilder für die Klassen `person` und `vehicle`\n",
    "*Bilder aus den Megadetector Vorhersagen*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_img_cat1 = df_images_clean[df_images_clean['category'] == 'animal']['file']\n",
    "lst_img_cat1 = lst_img_cat1.reset_index(drop=True)\n",
    "lst_img_cat1 = [image_name.replace('.jpg', '') for image_name in lst_img_cat1]\n",
    "lst_img_cat1\n",
    "\n",
    "lst_img_cat2 = df_images_clean[df_images_clean['category'] == 'person']['file']\n",
    "lst_img_cat2 = lst_img_cat2.reset_index(drop=True)\n",
    "lst_img_cat2 = [image_name.replace('.jpg', '') for image_name in lst_img_cat2]\n",
    "lst_img_cat2\n",
    "\n",
    "lst_img_cat3 = df_images_clean[df_images_clean['category'] == 'vehicle']['file']\n",
    "lst_img_cat3 = lst_img_cat3.reset_index(drop=True)\n",
    "lst_img_cat3 = [image_name.replace('.jpg', '') for image_name in lst_img_cat3]\n",
    "lst_img_cat3\n",
    "\n",
    "path_img_train = '../competition_data/'\n",
    "path_img_mega = './train_features_detection_th01/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Ansicht `person`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_lst_img_cat2 = random.sample(lst_img_cat2, 6)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 6))\n",
    "\n",
    "# iterate through each bad image\n",
    "for idx, (img_id, ax) in enumerate(zip(random_lst_img_cat2, axes.flat)):\n",
    "    # get image label\n",
    "    img_label = train_features_label.loc[img_id]['label']\n",
    "    # reads the filepath and returns a numpy array\n",
    "    img = mpimg.imread(path_img_mega + str(img_id).upper() + '_detections.jpg')\n",
    "    # get category\n",
    "    cat, conf = df_images_clean.loc[img_id]['category'], df_images_clean.loc[img_id]['max_detection_conf'], \n",
    "    # plot etc\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"{img_id} | {img_label} | {cat} | Conf: {conf:2f}\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Ansicht `vehicle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_lst_img_cat3 = random.sample(lst_img_cat3, 6) \n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 6))\n",
    "\n",
    "# iterate through each bad image\n",
    "for idx, (img_id, ax) in enumerate(zip(random_lst_img_cat3, axes.flat)):\n",
    "    # get image label\n",
    "    img_label = train_features_label.loc[img_id]['label']\n",
    "    # reads the filepath and returns a numpy array\n",
    "    img = mpimg.imread(path_img_mega + str(img_id).upper() + '_detections.jpg')\n",
    "    # get category\n",
    "    cat, conf = df_images_clean.loc[img_id]['category'], df_images_clean.loc[img_id]['max_detection_conf'], \n",
    "    # plot etc\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"{img_id} | {img_label} | {cat} | Conf: {conf:2f}\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Ansicht `animal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_lst_img_cat1 = random.sample(lst_img_cat1, 12)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 15))\n",
    "\n",
    "# iterate through each bad image\n",
    "for idx, (img_id, ax) in enumerate(zip(random_lst_img_cat1, axes.flat)):\n",
    "    # get image label\n",
    "    img_label = train_features_label.loc[img_id]['label']\n",
    "    # reads the filepath and returns a numpy array\n",
    "    img = mpimg.imread(path_img_mega + str(img_id).upper() + '_detections.jpg')\n",
    "    # get category\n",
    "    cat, conf = df_images_clean.loc[img_id]['category'], df_images_clean.loc[img_id]['max_detection_conf'], \n",
    "    # plot etc\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"{img_id} | {img_label} | {cat} | Conf: {conf:2f}\", fontsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beispiele für Falschklassifikation mit hoher Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missclassification_findings = ['ZJ010981', 'ZJ014854', 'ZJ003542']\n",
    "random_miss_class= random.sample(missclassification_findings, 3)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 12))\n",
    "\n",
    "# iterate through each bad image\n",
    "for idx, (img_id, ax) in enumerate(zip(random_miss_class, axes.flat)):\n",
    "    # get image label\n",
    "    img_label = train_features_label.loc[img_id]['label']\n",
    "    # reads the filepath and returns a numpy array\n",
    "    img = mpimg.imread(path_img_mega + str(img_id).upper() + '_detections.jpg')\n",
    "    # get category\n",
    "    cat, conf = df_images_clean.loc[img_id]['category'], df_images_clean.loc[img_id]['max_detection_conf'], \n",
    "    # plot etc\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"{img_id} | {img_label} | {cat} | Conf: {conf:2f}\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Bbox und Bildlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_bbox_label(label_path:str=\"../eda/train_features_label.csv\", threshold_bbox:float=0.4, filter_th=True):\n",
    "    '''\n",
    "    label_path: path for images and label csv\n",
    "    threshold_bbox: set confidence threshold\n",
    "    The function cleans the Megadetector JSON file, removes the bounding boxes for\n",
    "    confidence levels lower than the specified threshold. Creates a dataframe with\n",
    "    Image name, labels and bounding boxes\n",
    "    '''\n",
    "    train_features_label = pd.read_csv(label_path, index_col='id')\n",
    "\n",
    "    df_images_th = get_clean_dataframe_from_json(threshold_bbox, save_csv=False, filter_th=filter_th)\n",
    "    df_images_th_label = train_features_label.merge(df_images_th, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    df_images_th_label['bbox_true'] = df_images_th_label['bbox_normalized'].notnull()\n",
    "\n",
    "    return df_images_th_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test threshold\n",
    "# threshold = 0.4\n",
    "# df_images_th04_label = get_df_bbox_label(threshold_bbox=threshold, filter_th=True)\n",
    "# display(df_images_th04_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prüfe verschiedene Thresholds für Megadetector Confidence\n",
    "Es ist schwierig die Qualität der Bounding Boxen quantitativ zu prüfen. Folgend wird getestet, ob für für die einzelnen Tierklassen eine Boundingbox zu verschiedenen Threshold vorhanden ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_bbox_th_class(animal_class, thresholds:list):\n",
    "    '''\n",
    "    animal_class: class\n",
    "    thresholds: list with thresholds to be tested\n",
    "    Function filters df for class and counts the relative number [%]\n",
    "    of bbox available (bbox either false or true)\n",
    "    '''\n",
    "    bbox_true_list = []\n",
    "    bbox_fals_list = []\n",
    "    for th in tqdm(thresholds):\n",
    "        df_images_th_label = get_df_bbox_label(threshold_bbox=th)\n",
    "\n",
    "        df_images_class = df_images_th_label[df_images_th_label['label'] == animal_class]\n",
    "        relative_count = (df_images_class['bbox_true']\n",
    "                            .value_counts(normalize=True)\n",
    "                            .sort_values(ascending=False)\n",
    "                            .sort_index(ascending=False))\n",
    "\n",
    "        bbox_true_list.append(relative_count[0]*100)\n",
    "        bbox_fals_list.append(relative_count[1]*100)\n",
    "\n",
    "    return bbox_true_list, bbox_fals_list\n",
    "\n",
    "def plot_count_bbox_th_class(animal_class, thresholds, figsize=(6,4), save_plot=False):\n",
    "    blank_bbox_true, blank_bbox_false = count_bbox_th_class(animal_class, thresholds)\n",
    "\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "    plt.plot(thresholds, blank_bbox_true)\n",
    "    plt.suptitle('Relativer Count für Bbox zu verschiedenen Treshholds', fontsize=12)\n",
    "    plt.title(f'Klasse {animal_class}', fontsize=10)\n",
    "    plt.xlabel('thresholds', fontsize=8)\n",
    "    plt.ylabel('relativer Anteil [%]', fontsize=10)\n",
    "    plt.axvspan(thresholds[0], 0.4, facecolor='gray', alpha=0.2)\n",
    "    plt.axvspan(0.7, thresholds[-1], facecolor='gray', alpha=0.2)\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    if save_plots: plt.savefig(f'./plots/rel_count_bbox_{animal_class}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_count_bbox_th_class_all(thresholds, figsize=(12,6), save_plot=False): \n",
    "    classes = ['bird', 'monkey_prosimian', 'leopard', 'hog', 'civet_genet',\n",
    "            'antelope_duiker', 'blank', 'rodent']\n",
    "    \n",
    "    figure = plt.figure(figsize=figsize)    \n",
    "    for animal_class in tqdm(classes):\n",
    "        class_bbox_true, class_bbox_false = count_bbox_th_class(animal_class, thresholds)\n",
    "    \n",
    "        plt.plot(thresholds, class_bbox_true, label=f'{animal_class}')\n",
    "    \n",
    "    plt.suptitle('Relativer Count für Bbox zu verschiedenen Treshholds', fontsize=12)\n",
    "    plt.xlabel('thresholds', fontsize=8)\n",
    "    plt.ylabel('relativer Anteil [%]', fontsize=10)\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.21, 1))\n",
    "    plt.axvspan(thresholds[0], 0.4, facecolor='gray', alpha=0.5)\n",
    "    plt.axvspan(0.7, thresholds[-1], facecolor='gray', alpha=0.2)\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    if save_plots: plt.savefig(f'./plots/rel_count_bbox_all_classes.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test plots\n",
    "df_images_th_label = get_df_bbox_label(threshold_bbox=0.7)\n",
    "\n",
    "df_images_class = df_images_th_label[df_images_th_label['label'] == 'blank']\n",
    "df_images_class['bbox_true'].value_counts(normalize=True).sort_values(ascending=False).sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prüfe Klasse `blank`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thresholds = [0.4, 0.5, 0.6, 0.7]\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime: ca. 5min\n",
    "# plot_count_bbox_th_class('blank', thresholds, save_plot=save_plots)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Megadetector erkennt die `blank` Bilder sehr gut. Mit einem Threshold von `0.7` werden nur zu 0.6% Bounding Boxen vorhergesagt, somit werden zu 99.3% keine Tier auf der Klasse `blank` erkannt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prüfe `alle` Klassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime: ca. 12min\n",
    "#plot_count_bbox_th_class_all(thresholds, save_plot=save_plots)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das erkennen der einzelnen Tierklassen ist oben abgebildet. Wie zu erwarten sinken die Anzahl Bounding Boxen mit steigendem Threshold. Ein guter Threshold scheint sich zwischen `0.4` und `0.7` zu finden. \n",
    "Folgend werden csv Files zu unterschiedlichen Konfidenz-Thresholds gespeichert, somit kann ein optimaler Wert auch durch Modelltests gefunden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speichere CSV File\n",
    "speichere Megadetector Bbox und Tierlabel als csv datei für verschiedene Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_csv_file:\n",
    "    df_images_label_all_bbox = get_df_bbox_label(threshold_bbox=0.4, filter_th=False)\n",
    "    df_images_label_all_bbox.reset_index(drop=False).to_csv(f'megadetector_image_detection_all_bbox.csv', index=False)\n",
    "\n",
    "    thresholds_save_csv = [0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "    for th in thresholds_save_csv:\n",
    "        df_images_th_label = get_df_bbox_label(threshold_bbox=th)\n",
    "        df_images_th_label.to_csv(f'./bbox_csv/image_label_bbox_th{str(th).replace(\".\", \"\")}.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilder auf Bounding boxen zuschneiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_to_normalized_bbox(image_path, normalized_bbox):\n",
    "    image = Image.open(image_path)\n",
    "    image_width, image_height = image.size\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    image_tensor = to_tensor(image)\n",
    "\n",
    "    x, y, width, height = normalized_bbox\n",
    "    remove_bbox_xy = 4\n",
    "    remove_bbox_wh = remove_bbox_xy * 2\n",
    "    x = int(np.round(x * image_width, 0)) + remove_bbox_xy\n",
    "    y = int(np.round(y * image_height, 0)) + remove_bbox_xy\n",
    "    width = int(np.round(width * image_width, 0)) - remove_bbox_wh\n",
    "    height = int(np.round(height * image_height, 0)) - remove_bbox_wh\n",
    "\n",
    "    cropped_image_tensor = image_tensor[:, y:y+height, x:x+width]\n",
    "    to_pil = transforms.ToPILImage()\n",
    "    cropped_image = to_pil(cropped_image_tensor)\n",
    "    return cropped_image\n",
    "\n",
    "image_path = \"../megadetector/train_features_detection_th01/zj000000_detections.jpg\"\n",
    "normalized_bbox = (0.1093, 0.5888, 0.0802, 0.1851)\n",
    "cropped_image = crop_image_to_normalized_bbox(image_path, normalized_bbox)\n",
    "display(cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_to_normalized_bbox(image, normalized_bbox):\n",
    "    y,x,height,width = (43, 4, 470, 256) # transform_bbox(image, normalized_bbox)\n",
    "    image_tensor = transforms.ToTensor()(image)\n",
    "    return transforms.ToPILImage()((transforms.functional.crop(image_tensor,y,x,height,width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"megadetector_image_detection_all_bbox.csv\")\n",
    "df = df[df[\"id\"].duplicated()==False].reset_index()\n",
    "\n",
    "bbox_transformed = []\n",
    "for idx in range(len(df)):\n",
    "    if df.iloc[idx][\"bbox_true\"]:\n",
    "        path = r\"../competition_data/\" + df.iloc[idx][\"filepath\"]\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        normalized_bbox = ast.literal_eval(df.iloc[idx]['bbox'])\n",
    "        bbox_transformed.append(transform_bbox(image, normalized_bbox))\n",
    "    else:\n",
    "        bbox_transformed.append(pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"megadetector_image_detection_all_bbox.csv\")\n",
    "df = df[df[\"id\"].duplicated()==False]\n",
    "\n",
    "id= 16102\n",
    "\n",
    "path = r\"../competition_data/\" + df.iloc[id][\"filepath\"]\n",
    "image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "\n",
    "data_path = \"../megadetector/train_features_detection_th01/\"\n",
    "image_path = f'{data_path}{df[\"id\"][id]}'\n",
    "\n",
    "normalized_bbox = ast.literal_eval(df.iloc[id]['bbox'])\n",
    "cropped_image = crop_image_to_normalized_bbox(image, normalized_bbox)\n",
    "\n",
    "display(image)\n",
    "display(cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tierli_ahluege-kxyn7EyL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
